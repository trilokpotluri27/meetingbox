ANTHROPIC_API_KEY=sk-ant-api03-your-key-here

# Optional: override default models/settings in services
AI_MODEL=claude-sonnet-4-20250514
AI_MAX_TOKENS=2000

# Local LLM model for Ollama (used by "Summarize Locally" button)
# Options: phi3:mini (best quality/size ratio, ~2.5GB RAM), qwen2.5:3b, tinyllama
# You must pull the model first: docker compose exec ollama ollama pull phi3:mini
LOCAL_LLM_MODEL=phi3:mini

# ── Device UI (OLED touchscreen) ─────────────────────────────────
# Set to 1 to run UI without backend (for testing)
MOCK_BACKEND=0

# Display settings
DISPLAY=:0
DISPLAY_WIDTH=480
DISPLAY_HEIGHT=320
FULLSCREEN=1

