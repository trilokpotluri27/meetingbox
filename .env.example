ANTHROPIC_API_KEY=sk-ant-api03-your-key-here

# Optional: override default models/settings in services
AI_MODEL=claude-sonnet-4-20250514
AI_MAX_TOKENS=2000

# Local LLM model for Ollama (used by "Summarize Locally" button)
# Options: llama3.1:8b (best quality), phi3:mini (lighter, ~2.5GB RAM), mistral:7b
# You must pull the model first: docker compose exec ollama ollama pull llama3.1:8b
LOCAL_LLM_MODEL=llama3.1:8b

